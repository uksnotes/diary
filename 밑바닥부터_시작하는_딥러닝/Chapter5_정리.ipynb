{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter5_정리.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO4pZ0BO8iPa"
      },
      "source": [
        "## **5.1 계산 그래프**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tVtj-y98n8b"
      },
      "source": [
        "- 계산 그래프 노드와 에지 노드는 + - 표기 에지 -> 표기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbAvW0Z583-C"
      },
      "source": [
        "- 100 * 2 * 1.1 = 220 \n",
        "- (100) -> (2) -> node(*) -> (200) -> 1.1 -> node(*)-> (220) \n",
        "- 순전파 forward propagation : 계산이 왼쪽에서 오른쪽으로 진행 \n",
        "- 역전파 backward propagation : 순전파와 반대로 오른쪽에서 왼쪽으로 진행\n",
        "- 국소적 계산 : 자신과 직접 관련된 것들을 넘겨 준다 \n",
        "- 예시 : node(*)는 두 숫자를 곱한다라는 국소적 계산을 실시 \n",
        "- 단순한 국소적 계산이 모여 복잡한 계산 구현 가능 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8VFC0kgLuTA"
      },
      "source": [
        "## 그림 5.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVF0rt6zL0JT"
      },
      "source": [
        "- 역전파인 경우 1 -> 1.1 -> 2.2 반대 순으로  수행 굵은선으로 표기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0XFf-vMMGTn"
      },
      "source": [
        "## **5.2 연쇄법칙**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpLHiP-LMc2A"
      },
      "source": [
        "- z = t^2 \n",
        "- t = x + y\n",
        "- az/ax = az/dt*at/ax 로 표기 \n",
        "- az/ax = 2t*1 = 2(x+y)*1로 나타낼 수 있음\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I750e8FQz_j4"
      },
      "source": [
        "그림 5-7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMzF57x80Cag"
      },
      "source": [
        "- 역전파로 진행시 z -> az/az(derivative) -> az/az*az/at = az/at -> az/az*az/at*at/ax = az/ax x에 대한 z의 미분 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fce934851kVU"
      },
      "source": [
        "그림 5-8 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXeXG4p31kYT"
      },
      "source": [
        "## **5.3 역전파**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFS4kMMV1kak"
      },
      "source": [
        "- 덧셈 노드 역전파 : 똑같은 값을 전달 \n",
        "- 곱셉 노드 역전파 : x와 y 값을 바꿔줌"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZHIJkbj815w"
      },
      "source": [
        "def backward(dout):  # 덧셈 역전파 \n",
        "    dx = dout * 1 \n",
        "    dy = dout * 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqZSFSUr8DAO"
      },
      "source": [
        "def backward(dout):   # 곱셈 역전파 \n",
        "    dx = dout* self.y # x와 y를 바꿔준다 \n",
        "    dy = dout* self.x "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdgNMW9m8WA1"
      },
      "source": [
        "- 10과 5가 곱해져서 50이 형성되지만 역전파로 진행했을 때 \n",
        "- 50에 1.3이라는 전류가 흐를 때 \n",
        "- 5에는 10 *1.3 = 13이라는 전류가 흐름 \n",
        "- 10에는 1.3*5 = 6.5 전류가 흐름"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjC9umuIBFPh"
      },
      "source": [
        "## **5.5** 활성화 함수 계층 구현하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnKCsAtvBKfa"
      },
      "source": [
        "- y = x (x > 0) , 0 (x <= 0)\n",
        "- ay = 1 (x > 0), 0 (x <= 0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAhUZeeyBIzi"
      },
      "source": [
        "class Relu:\n",
        "    def __init__(self):\n",
        "        self.mask = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.mask = (x <= 0)\n",
        "        out = x.copy()\n",
        "        out[self.mask] = 0\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dout[self.mask] = 0\n",
        "        dx = dout\n",
        "\n",
        "        return dx   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smHuFkaIBaV8"
      },
      "source": [
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.out = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = sigmoid(x)\n",
        "        self.out = out\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = dout * (1.0 - self.out) * self.out\n",
        "\n",
        "        return dx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALxSt5bvGuY5"
      },
      "source": [
        "## **5.6 Affine/Softmax 계층 구현**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LER4RqkpG2ou"
      },
      "source": [
        "- np.dot(x, w) = 0\n",
        "- (2, ) dot w (2, 3) = (3, ) \n",
        "- 앞에 2 -> 2 3 -> 3 매칭 \n",
        "- 순전파 때 수행하는 곱을 어파인 변환이라고 칭함 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD9Su_nDQasC"
      },
      "source": [
        "- a1 -> softmax y1 -> cross entropy error t1 -> L이 나오는 경우\n",
        "- 역전파 경우 y1 - t1 값을 반환 \n",
        "- (0, 1, 0) 정답 레이블일 때 \n",
        "- (0.3, 0.2, 0.5) softmax 레이블 \n",
        "- 정답률 20%가 되어 신경망 인식에 어려움 \n",
        "- 역전파 경우 (0.3, -0.8, 0.5) 큰 오차를 통해 신경망이 인식\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3tLwfllQauS"
      },
      "source": [
        "## **5.7 구현** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RUN-K_tTzs4"
      },
      "source": [
        "import sys, os\n",
        "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
        "import numpy as np\n",
        "from common.layers import *\n",
        "from common.gradient import numerical_gradient\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "class TwoLayerNet:\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
        "        # 가중치 초기화\n",
        "        self.params = {}\n",
        "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "        self.params['b1'] = np.zeros(hidden_size)\n",
        "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) \n",
        "        self.params['b2'] = np.zeros(output_size)\n",
        "\n",
        "        # 계층 생성\n",
        "        self.layers = OrderedDict()\n",
        "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
        "        self.layers['Relu1'] = Relu()\n",
        "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
        "\n",
        "        self.lastLayer = SoftmaxWithLoss()\n",
        "        \n",
        "    def predict(self, x):\n",
        "        for layer in self.layers.values():\n",
        "            x = layer.forward(x)\n",
        "        \n",
        "        return x\n",
        "        \n",
        "    # x : 입력 데이터, t : 정답 레이블\n",
        "    def loss(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        return self.lastLayer.forward(y, t)\n",
        "    \n",
        "    def accuracy(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        y = np.argmax(y, axis=1)\n",
        "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
        "        \n",
        "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "        return accuracy\n",
        "        \n",
        "    # x : 입력 데이터, t : 정답 레이블\n",
        "    def numerical_gradient(self, x, t):\n",
        "        loss_W = lambda W: self.loss(x, t)\n",
        "        \n",
        "        grads = {}\n",
        "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "        \n",
        "        return grads\n",
        "        \n",
        "    def gradient(self, x, t):\n",
        "        # forward\n",
        "        self.loss(x, t)\n",
        "\n",
        "        # backward\n",
        "        dout = 1\n",
        "        dout = self.lastLayer.backward(dout)\n",
        "        \n",
        "        layers = list(self.layers.values())\n",
        "        layers.reverse()\n",
        "        for layer in layers:\n",
        "            dout = layer.backward(dout)\n",
        "\n",
        "        # 결과 저장\n",
        "        grads = {}\n",
        "        grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
        "        grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
        "\n",
        "        return grads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUkmHDzmWOWD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}